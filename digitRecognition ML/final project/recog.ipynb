{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22cc0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#  to split the data of training and testing sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba4dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# conversion of class vectors to matrices of  binary class \n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f2aa79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a27c6bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 39s 77ms/step - loss: 0.2069 - accuracy: 0.9359 - val_loss: 0.0476 - val_accuracy: 0.9853\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 35s 74ms/step - loss: 0.0666 - accuracy: 0.9798 - val_loss: 0.0349 - val_accuracy: 0.9898\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 35s 75ms/step - loss: 0.0467 - accuracy: 0.9854 - val_loss: 0.0263 - val_accuracy: 0.9905\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 35s 75ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 0.0285 - val_accuracy: 0.9907\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 35s 75ms/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 0.0229 - val_accuracy: 0.9923\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 35s 75ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0248 - val_accuracy: 0.9912\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 35s 75ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0227 - val_accuracy: 0.9925\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 35s 75ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0273 - val_accuracy: 0.9916\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 36s 77ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0263 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 36s 78ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0220 - val_accuracy: 0.9934\n",
      "The model has successfully trained\n",
      "Saving the bot as mnist.h5\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "print(\"The model has successfully trained\")\n",
    "model.save('new_mnist.h5')\n",
    "print(\"Saving the bot as mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a18509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.021992508322000504\n",
      "Test accuracy: 0.993399977684021\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536c1b42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "finalArray = np.argmax(model.predict(x_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "291affba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 9 2 ... 2 2 8]\n"
     ]
    }
   ],
   "source": [
    "print(finalArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a702d31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce29b61fc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6a9329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 10:11:25.860 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run e:\\Python 3.10.5 (64-bit)\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import load_model\n",
    "# model2=keras.models.load_model(\"offlineModel.h5py\")\n",
    "#this is how we load the already saved model\n",
    "# model2.evaluate(X_test,y_test)\n",
    "\n",
    "model = keras.models.load_model(\"model.h5\")\n",
    "img = st.file_uploader(\"please enter an image\")\n",
    "# # model.evaluate(X_test, y_test)\n",
    "\n",
    "# image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "# image = cv2.resize(image, (28,28))\n",
    "# image = 255-image          #inverts image. Always gets read inverted.\n",
    "\n",
    "# plt.imshow(image.reshape(28, 28),cmap='Greys')\n",
    "# plt.show()\n",
    " pred = model.predict(image.reshape(1, 28, 28, 1), batch_size=1)\n",
    "\n",
    "# print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d421ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af388e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0585ab582f4a2aaee36fc90d6bf8f5cfbae266ba6d512fc2b11359b6887e160b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
